{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89536a9-f698-4c27-8d2c-d0db3c3b146c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Using cached cvlib-0.2.6.tar.gz (10.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from cvlib) (1.19.5)\n",
      "Collecting progressbar\n",
      "  Using cached progressbar-2.5.tar.gz (10 kB)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from cvlib) (2.25.1)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\lib\\site-packages (from cvlib) (8.2.0)\n",
      "Requirement already satisfied: imageio in c:\\anaconda\\lib\\site-packages (from cvlib) (2.9.0)\n",
      "Requirement already satisfied: imutils in c:\\anaconda\\lib\\site-packages (from cvlib) (0.5.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->cvlib) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->cvlib) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->cvlib) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests->cvlib) (4.0.0)\n",
      "Building wheels for collected packages: cvlib, progressbar\n",
      "  Building wheel for cvlib (setup.py): started\n",
      "  Building wheel for cvlib (setup.py): finished with status 'done'\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.6-py3-none-any.whl size=10044621 sha256=f21dc3447720244cecc0017361e2bc7d0ece0c9c1533f77f3eed215ac5a72b6d\n",
      "  Stored in directory: c:\\users\\womon\\appdata\\local\\pip\\cache\\wheels\\ab\\cb\\f5\\2d027cae91342418d4a84c6955d080c2e361b60bb72db3f71c\n",
      "  Building wheel for progressbar (setup.py): started\n",
      "  Building wheel for progressbar (setup.py): finished with status 'done'\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12075 sha256=8cfc480dbe2822f570ad6d172d07de1b1b425ed5b07880c028789e404baec3e3\n",
      "  Stored in directory: c:\\users\\womon\\appdata\\local\\pip\\cache\\wheels\\2c\\67\\ed\\d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
      "Successfully built cvlib progressbar\n",
      "Installing collected packages: progressbar, cvlib\n",
      "Successfully installed cvlib-0.2.6 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install cvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6df024d-46c9-4942-909f-c8953562a44e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[271, 154, 477, 414]]\n",
      "[0.9932613]\n",
      "[[268, 153, 470, 404]]\n",
      "[0.87448716]\n",
      "[[264, 145, 472, 401]]\n",
      "[0.9872892]\n",
      "[[257, 138, 468, 386]]\n",
      "[0.95630586]\n",
      "[[251, 138, 468, 372]]\n",
      "[0.9537589]\n",
      "[[247, 135, 464, 378]]\n",
      "[0.9447129]\n",
      "[[245, 134, 464, 376]]\n",
      "[0.9476336]\n",
      "[[245, 135, 465, 371]]\n",
      "[0.9483039]\n",
      "[[247, 133, 467, 378]]\n",
      "[0.9242022]\n",
      "[[254, 119, 466, 411]]\n",
      "[0.9498972]\n",
      "[[256, 114, 467, 420]]\n",
      "[0.750546]\n",
      "[[254, 136, 468, 391]]\n",
      "[0.8120884]\n",
      "[[254, 137, 470, 370]]\n",
      "[0.95845795]\n",
      "[[254, 135, 469, 367]]\n",
      "[0.9791175]\n",
      "[[255, 126, 466, 374]]\n",
      "[0.9846838]\n",
      "[[253, 129, 459, 371]]\n",
      "[0.97755355]\n",
      "[[248, 129, 447, 376]]\n",
      "[0.9594067]\n",
      "[[237, 134, 429, 375]]\n",
      "[0.6424752]\n",
      "[[232, 137, 426, 381]]\n",
      "[0.83306515]\n",
      "[[227, 143, 422, 383]]\n",
      "[0.9521444]\n",
      "[[226, 147, 416, 384]]\n",
      "[0.9977864]\n",
      "[[225, 147, 414, 384]]\n",
      "[0.99739945]\n",
      "[[225, 155, 405, 386]]\n",
      "[0.9997552]\n",
      "[[225, 160, 403, 389]]\n",
      "[0.9978034]\n",
      "[[226, 166, 401, 393]]\n",
      "[0.86104316]\n",
      "[[228, 174, 401, 395]]\n",
      "[0.99893814]\n",
      "[[232, 177, 402, 396]]\n",
      "[0.9996201]\n",
      "[[235, 178, 402, 399]]\n",
      "[0.99823123]\n",
      "[[236, 180, 403, 396]]\n",
      "[0.99627006]\n",
      "[[236, 178, 404, 395]]\n",
      "[0.9960382]\n",
      "[[235, 179, 403, 403]]\n",
      "[0.9984633]\n",
      "[[235, 177, 402, 406]]\n",
      "[0.998716]\n",
      "[[226, 182, 398, 432]]\n",
      "[0.99292046]\n",
      "[[227, 188, 399, 425]]\n",
      "[0.9945775]\n",
      "[[228, 184, 400, 433]]\n",
      "[0.99617493]\n",
      "[[229, 186, 401, 427]]\n",
      "[0.99708253]\n",
      "[[231, 194, 404, 429]]\n",
      "[0.98777896]\n",
      "[[230, 192, 410, 453]]\n",
      "[0.9636158]\n",
      "[[234, 192, 408, 447]]\n",
      "[0.9954058]\n",
      "[[236, 182, 409, 443]]\n",
      "[0.99391514]\n",
      "[[240, 178, 411, 428]]\n",
      "[0.99541533]\n",
      "[[241, 178, 414, 421]]\n",
      "[0.9933296]\n",
      "[[245, 179, 418, 410]]\n",
      "[0.9673665]\n",
      "[[249, 184, 425, 402]]\n",
      "[0.96351576]\n",
      "[[252, 184, 427, 394]]\n",
      "[0.9766608]\n",
      "[[252, 185, 428, 391]]\n",
      "[0.9802399]\n",
      "[[252, 185, 430, 389]]\n",
      "[0.9870488]\n",
      "[[255, 184, 432, 398]]\n",
      "[0.9849985]\n",
      "[[255, 185, 434, 400]]\n",
      "[0.98420966]\n",
      "[[256, 187, 434, 401]]\n",
      "[0.9819802]\n",
      "[[255, 189, 434, 399]]\n",
      "[0.985727]\n",
      "[[256, 188, 434, 398]]\n",
      "[0.98709065]\n",
      "[[254, 189, 432, 395]]\n",
      "[0.9857314]\n",
      "[[252, 186, 430, 397]]\n",
      "[0.98375165]\n",
      "[[251, 185, 429, 392]]\n",
      "[0.9853178]\n",
      "[[254, 185, 432, 391]]\n",
      "[0.98866975]\n",
      "[[257, 184, 435, 393]]\n",
      "[0.9927296]\n",
      "[[259, 185, 435, 389]]\n",
      "[0.99515533]\n",
      "[[263, 189, 440, 388]]\n",
      "[0.99548763]\n",
      "[[265, 189, 441, 386]]\n",
      "[0.9948832]\n",
      "[[269, 185, 443, 383]]\n",
      "[0.9959359]\n",
      "[[273, 184, 449, 387]]\n",
      "[0.99910384]\n",
      "[[277, 182, 452, 394]]\n",
      "[0.9989735]\n",
      "[[281, 180, 454, 387]]\n",
      "[0.99916685]\n",
      "[[283, 182, 454, 393]]\n",
      "[0.9990814]\n",
      "[[286, 184, 457, 393]]\n",
      "[0.99908996]\n",
      "[[285, 183, 457, 392]]\n",
      "[0.9988433]\n",
      "[[286, 183, 456, 392]]\n",
      "[0.9988477]\n",
      "[[285, 182, 456, 391]]\n",
      "[0.9986914]\n",
      "[[288, 182, 458, 389]]\n",
      "[0.9990428]\n",
      "[[287, 183, 460, 392]]\n",
      "[0.9988096]\n",
      "[[289, 180, 461, 398]]\n",
      "[0.9990325]\n",
      "[[292, 179, 466, 396]]\n",
      "[0.99835]\n",
      "[[295, 178, 467, 399]]\n",
      "[0.99853015]\n",
      "[[299, 181, 471, 394]]\n",
      "[0.99429387]\n",
      "[[302, 181, 474, 391]]\n",
      "[0.9924982]\n",
      "[[306, 178, 478, 401]]\n",
      "[0.9807734]\n",
      "[[307, 179, 478, 400]]\n",
      "[0.9767397]\n",
      "[[308, 178, 481, 404]]\n",
      "[0.968907]\n",
      "[[306, 178, 479, 405]]\n",
      "[0.95505196]\n",
      "[[302, 180, 476, 397]]\n",
      "[0.9845138]\n",
      "[[299, 175, 474, 396]]\n",
      "[0.99293596]\n",
      "[[290, 175, 465, 388]]\n",
      "[0.9973705]\n",
      "[[285, 177, 460, 389]]\n",
      "[0.99850523]\n",
      "[[282, 179, 455, 378]]\n",
      "[0.99552625]\n",
      "[[276, 178, 447, 387]]\n",
      "[0.9972402]\n",
      "[[270, 179, 444, 387]]\n",
      "[0.99268144]\n",
      "[[263, 174, 438, 401]]\n",
      "[0.9566831]\n",
      "[[259, 177, 438, 382]]\n",
      "[0.9708138]\n",
      "[[256, 179, 434, 383]]\n",
      "[0.97174394]\n",
      "[[252, 176, 431, 383]]\n",
      "[0.9740239]\n",
      "[[251, 177, 428, 391]]\n",
      "[0.9727288]\n",
      "[[242, 173, 421, 386]]\n",
      "[0.9928744]\n",
      "[[239, 172, 417, 383]]\n",
      "[0.9970156]\n",
      "[[234, 173, 412, 377]]\n",
      "[0.99882525]\n",
      "[[233, 168, 411, 384]]\n",
      "[0.99962497]\n",
      "[[230, 171, 407, 384]]\n",
      "[0.999828]\n",
      "[[225, 167, 403, 387]]\n",
      "[0.99992514]\n",
      "[[222, 172, 393, 385]]\n",
      "[0.99987376]\n",
      "[[219, 169, 390, 385]]\n",
      "[0.9998604]\n",
      "[[218, 169, 386, 383]]\n",
      "[0.99972516]\n",
      "[[215, 165, 379, 382]]\n",
      "[0.9995028]\n",
      "[[210, 167, 371, 383]]\n",
      "[0.9977798]\n",
      "[[206, 165, 362, 382]]\n",
      "[0.9881301]\n",
      "[[203, 163, 356, 388]]\n",
      "[0.9881151]\n",
      "[[200, 165, 354, 393]]\n",
      "[0.9807382]\n",
      "[[199, 165, 353, 392]]\n",
      "[0.9728013]\n",
      "[[201, 164, 355, 389]]\n",
      "[0.9810446]\n",
      "[[201, 164, 358, 384]]\n",
      "[0.98319936]\n",
      "[[204, 162, 364, 381]]\n",
      "[0.990248]\n",
      "[[208, 165, 371, 377]]\n",
      "[0.99642986]\n",
      "[[211, 166, 379, 381]]\n",
      "[0.9991691]\n",
      "[[211, 169, 385, 381]]\n",
      "[0.9997069]\n",
      "[[219, 167, 397, 386]]\n",
      "[0.9999114]\n",
      "[[225, 171, 401, 379]]\n",
      "[0.99983525]\n",
      "[[231, 168, 407, 384]]\n",
      "[0.99963427]\n",
      "[[234, 163, 410, 397]]\n",
      "[0.99860317]\n",
      "[[236, 164, 410, 393]]\n",
      "[0.99767417]\n",
      "[[237, 159, 409, 395]]\n",
      "[0.99848]\n",
      "[[237, 154, 408, 401]]\n",
      "[0.9985543]\n",
      "[[236, 155, 407, 396]]\n",
      "[0.99903333]\n",
      "[[233, 159, 403, 395]]\n",
      "[0.9932929]\n",
      "[[230, 173, 399, 396]]\n",
      "[0.96740246]\n",
      "[[227, 179, 399, 402]]\n",
      "[0.7631027]\n",
      "[[227, 183, 398, 404]]\n",
      "[0.7871208]\n",
      "[[226, 181, 396, 400]]\n",
      "[0.75045943]\n",
      "[[225, 183, 395, 403]]\n",
      "[0.77861094]\n",
      "[[227, 184, 393, 408]]\n",
      "[0.8816603]\n",
      "[[225, 193, 393, 410]]\n",
      "[0.508835]\n",
      "[[225, 188, 390, 420]]\n",
      "[0.55042946]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[[231, 176, 398, 335]]\n",
      "[0.69505596]\n",
      "[[232, 177, 403, 340]]\n",
      "[0.9340885]\n",
      "[[234, 180, 406, 336]]\n",
      "[0.9944096]\n",
      "[[235, 178, 408, 344]]\n",
      "[0.9968753]\n",
      "[[237, 181, 408, 351]]\n",
      "[0.998104]\n",
      "[[237, 179, 409, 354]]\n",
      "[0.99905235]\n",
      "[[237, 178, 409, 361]]\n",
      "[0.9966191]\n",
      "[[237, 177, 411, 373]]\n",
      "[0.99696976]\n",
      "[[237, 178, 413, 383]]\n",
      "[0.9976673]\n",
      "[[237, 179, 413, 387]]\n",
      "[0.99840194]\n",
      "[[235, 183, 413, 397]]\n",
      "[0.99919266]\n",
      "[[235, 182, 413, 403]]\n",
      "[0.99940515]\n",
      "[[232, 184, 412, 408]]\n",
      "[0.9998116]\n",
      "[[231, 186, 410, 409]]\n",
      "[0.9998079]\n",
      "[[229, 188, 409, 409]]\n",
      "[0.99982136]\n",
      "[[226, 189, 408, 414]]\n",
      "[0.9998963]\n",
      "[[222, 189, 405, 417]]\n",
      "[0.9999014]\n",
      "[[217, 188, 400, 415]]\n",
      "[0.9999311]\n",
      "[[213, 187, 392, 414]]\n",
      "[0.99992216]\n",
      "[[209, 187, 388, 416]]\n",
      "[0.9998216]\n",
      "[[207, 184, 385, 416]]\n",
      "[0.9998456]\n",
      "[[208, 183, 385, 415]]\n",
      "[0.99989283]\n",
      "[[208, 185, 388, 414]]\n",
      "[0.99990106]\n",
      "[[210, 188, 390, 413]]\n",
      "[0.9997955]\n",
      "[[212, 187, 393, 404]]\n",
      "[0.9998379]\n",
      "[[218, 188, 398, 410]]\n",
      "[0.99960333]\n",
      "[[221, 183, 402, 438]]\n",
      "[0.99890745]\n",
      "[[223, 186, 403, 437]]\n",
      "[0.9991431]\n",
      "[[225, 189, 403, 418]]\n",
      "[0.997841]\n",
      "[[226, 191, 403, 423]]\n",
      "[0.99560744]\n",
      "[[223, 192, 402, 433]]\n",
      "[0.8800519]\n",
      "[[225, 194, 404, 434]]\n",
      "[0.90180904]\n",
      "[[228, 195, 405, 432]]\n",
      "[0.9539054]\n",
      "[[228, 193, 405, 431]]\n",
      "[0.9904937]\n",
      "[[230, 190, 406, 429]]\n",
      "[0.9963458]\n",
      "[[235, 189, 411, 413]]\n",
      "[0.99852306]\n",
      "[[237, 185, 413, 412]]\n",
      "[0.98980576]\n",
      "[[237, 185, 415, 410]]\n",
      "[0.9546403]\n",
      "[[241, 182, 418, 407]]\n",
      "[0.969586]\n",
      "[[244, 176, 423, 406]]\n",
      "[0.9815879]\n",
      "[[242, 172, 424, 407]]\n",
      "[0.97695506]\n",
      "[[240, 169, 419, 398]]\n",
      "[0.70688224]\n",
      "[[239, 170, 417, 397]]\n",
      "[0.63467133]\n",
      "[[237, 175, 418, 399]]\n",
      "[0.98422813]\n",
      "[[236, 174, 417, 397]]\n",
      "[0.9940169]\n",
      "[[233, 167, 415, 394]]\n",
      "[0.99621636]\n",
      "[[231, 165, 414, 396]]\n",
      "[0.99717146]\n",
      "[[230, 166, 413, 396]]\n",
      "[0.9982961]\n",
      "[[230, 162, 412, 396]]\n",
      "[0.9985196]\n",
      "[[228, 162, 412, 395]]\n",
      "[0.9984195]\n",
      "[[228, 163, 411, 393]]\n",
      "[0.99887663]\n",
      "[[229, 164, 412, 392]]\n",
      "[0.9987282]\n",
      "[[230, 166, 413, 392]]\n",
      "[0.99890494]\n",
      "[[230, 162, 414, 395]]\n",
      "[0.99902654]\n",
      "[[230, 161, 415, 394]]\n",
      "[0.9987159]\n",
      "[[230, 161, 416, 394]]\n",
      "[0.9981951]\n",
      "[[229, 160, 415, 395]]\n",
      "[0.99005204]\n",
      "[[229, 160, 415, 395]]\n",
      "[0.98758847]\n",
      "[[230, 159, 415, 393]]\n",
      "[0.9900035]\n",
      "[[229, 160, 415, 392]]\n",
      "[0.9926722]\n",
      "[[229, 160, 414, 394]]\n",
      "[0.99476177]\n",
      "[[229, 160, 413, 391]]\n",
      "[0.99639326]\n",
      "[[229, 159, 414, 393]]\n",
      "[0.99622595]\n",
      "[[229, 161, 413, 391]]\n",
      "[0.9961468]\n",
      "[[229, 161, 412, 392]]\n",
      "[0.9973003]\n",
      "[[228, 163, 411, 391]]\n",
      "[0.996572]\n",
      "[[227, 161, 410, 391]]\n",
      "[0.9967803]\n",
      "[[225, 163, 408, 388]]\n",
      "[0.99231213]\n"
     ]
    }
   ],
   "source": [
    "import cvlib as cv\n",
    "import cv2\n",
    "\n",
    " \n",
    "# open webcam (웹캠 열기)\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    " \n",
    "sample_num = 0    \n",
    "captured_num = 0\n",
    "    \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "    \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    sample_num = sample_num + 1\n",
    "    \n",
    "    if not status:\n",
    "        break\n",
    " \n",
    "    # 이미지 내 얼굴 검출\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "    \n",
    "    print(face)\n",
    "    print(confidence)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    " \n",
    " \n",
    "        if sample_num % 8  == 0:\n",
    "            captured_num = captured_num + 1\n",
    "            face_in_img = frame[startY:endY, startX:endX, :]\n",
    "            #cv2.imwrite('./mask/face'+str(captured_num)+'.jpg', face_in_img) # 마스크 미착용 데이터 수집시 주석처리\n",
    "            cv2.imwrite('./nomask/face'+str(captured_num)+'.jpg', face_in_img) # 마스크 미착용 데이터 수집시 주석해제\n",
    " \n",
    " \n",
    "    # display output\n",
    "    cv2.imshow(\"captured frames\", frame)        \n",
    "    \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816e2e41-4263-497b-9957-41b894f4c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 23s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "Number of layers in the base model:  175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 36,433,537\n",
      "Trainable params: 12,845,569\n",
      "Non-trainable params: 23,587,968\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 2s/step - loss: 0.6323 - accuracy: 0.6098 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1880 - accuracy: 0.9024 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0587 - accuracy: 0.9756 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    " \n",
    " \n",
    "path_dir1 = './nomask/'\n",
    "path_dir2 = './mask/'\n",
    " \n",
    "file_list1 = os.listdir(path_dir1) # path에 존재하는 파일 목록 가져오기\n",
    "file_list2 = os.listdir(path_dir2)\n",
    " \n",
    "file_list1_num = len(file_list1)\n",
    "file_list2_num = len(file_list2)\n",
    " \n",
    "file_num = file_list1_num + file_list2_num\n",
    " \n",
    " \n",
    "#%% 이미지 전처리\n",
    "num = 0;\n",
    "all_img = np.float32(np.zeros((file_num, 224, 224, 3))) \n",
    "all_label = np.float64(np.zeros((file_num, 1)))\n",
    " \n",
    "for img_name in file_list1:\n",
    "    img_path = path_dir1+img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 0 # nomask\n",
    "    num = num + 1\n",
    " \n",
    "for img_name in file_list2:\n",
    "    img_path = path_dir2+img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 1 # mask\n",
    "    num = num + 1\n",
    " \n",
    " \n",
    "# 데이터셋 섞기(적절하게 훈련되게 하기 위함) \n",
    "n_elem = all_label.shape[0]\n",
    "indices = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    " \n",
    "all_label = all_label[indices]\n",
    "all_img = all_img[indices]\n",
    " \n",
    " \n",
    "# 훈련셋 테스트셋 분할\n",
    "num_train = int(np.round(all_label.shape[0]*0.8))\n",
    "num_test = int(np.round(all_label.shape[0]*0.2))\n",
    " \n",
    "train_img = all_img[0:num_train, :, :, :]\n",
    "test_img = all_img[num_train:, :, :, :] \n",
    " \n",
    "train_label = all_label[0:num_train]\n",
    "test_label = all_label[num_train:]\n",
    " \n",
    " \n",
    " \n",
    "#%% \n",
    "# create the base pre-trained model\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    " \n",
    "base_model = ResNet50(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    "base_model.summary()\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    " \n",
    "flatten_layer = Flatten()\n",
    "dense_layer1 = Dense(128, activation='relu')\n",
    "bn_layer1 = BatchNormalization()\n",
    "dense_layer2 = Dense(1, activation=tf.nn.sigmoid)\n",
    " \n",
    "model = Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer1,\n",
    "        bn_layer1,\n",
    "        dense_layer2,\n",
    "        ])\n",
    " \n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "model.fit(train_img, train_label, epochs=10, batch_size=16, validation_data = (test_img, test_label))\n",
    " \n",
    " \n",
    "# save model\n",
    "model.save(\"model.h5\")\n",
    " \n",
    "print(\"Saved model to disk\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac29624-a10e-4f32-b578-2d210ec5fa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 36,433,537\n",
      "Trainable params: 12,845,569\n",
      "Non-trainable params: 23,587,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    " \n",
    " \n",
    "model = load_model('model.h5')\n",
    "model.summary()\n",
    " \n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    " \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            prediction = model.predict(x)\n",
    " \n",
    "            if prediction < 0.5: # 마스크 착용으로 판별되면, \n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                \n",
    "    # display output\n",
    "    cv2.imshow(\"mask nomask classify\", frame)\n",
    " \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
